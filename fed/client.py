"""
Representation of a client/supernode in a federated framework.
Performs both training and evaluation with a local pytorch MLP module that gets
its parameters from the server module.
"""
from typing import Callable, Optional
from collections import OrderedDict # Optional
from dataclasses import dataclass
from pathlib import Path
from time import time
import os

from flwr.app import ArrayRecord, Context, Message, MetricRecord, RecordDict
from flwr.clientapp import ClientApp

from opacus.grad_sample.grad_sample_module import GradSampleModule
from opacus.optimizers.optimizer import DPOptimizer
from torch.utils.data import DataLoader, TensorDataset
from torch import Tensor
import torch
import pandas as pd

from fed.continual_learning import ContinualLearning
from fed.differential_privacy import DifferentialPrivacy
from models.mlp import MLP, Adam, CosineAnnealingLR
from models.fed_metrics import FedMetrics

MAIN_PATH = Path().cwd()

@dataclass()
class ClientConfiguration:
    """Stores configurations from pyproject.toml"""
    def __init__(self, context: Context) -> None:
        device_str = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.device = torch.device(device_str)
        self.epochs = int(context.run_config['epochs'])
        self.batch_size = int(context.run_config['batch-size'])

        # Experience replay
        self.cl_enabled = bool(context.run_config['cl-enabled'])
        self.er_sample_rate = float(context.run_config['er-memory'])
        self.er_mix_ratio = float(context.run_config['er-mix-ratio'])
        self.ewc_lambda = float(context.run_config['ewc-lambda'])

        # Differential privacy
        self.dp_enabled = bool(context.run_config['dp-enabled'])
        self.clipping = float(context.run_config['clipping'])
        self.noise = float(context.run_config['noise'])
        self.delta = float(context.run_config['delta'])

class Client:
    """Acts as an interactive instance of a client."""
    def __init__(self, context: Context) -> None:
        self.config = ClientConfiguration(context)
        self.model: MLP = self._initialize_model(context)
        self.criterion = torch.nn.BCEWithLogitsLoss() # Automatically on device

        self.cl = ContinualLearning(
            er_filepath_identifier=os.getpid(), # or Node ID
            er_runtime_directory=MAIN_PATH / 'runtime',
            device=self.config.device
        )
        self.dp = DifferentialPrivacy()
        # Only training nodes can fetch epsilon.
        self.stored_epsilon: Optional[float] = None

        # Data cache (probably will be removed with CIC-IDS)
        self.dataframe: pd.DataFrame
        self.dataframe_path: Optional[Path] = None

    def _initialize_model(self, context: Context) -> MLP:
        widths = str(context.run_config['mlp-widths'])
        model = MLP(
            n_features=int(context.run_config['n-features']),
            hidden_widths=map(int, widths.split(',')),
            dropout=float(context.run_config['mlp-dropout']),
            weight_decay=float(context.run_config['mlp-weight-decay']),
            lr_max=float(context.run_config['mlp-lr-max']),
            lr_min=float(context.run_config['mlp-lr-min'])
        )
        return model.to(self.config.device)

    def update_model(self, parameters: dict[str, Tensor]) -> None:
        """
        Load a given MLP module's parameters into client's model.
        Automatically moves parameters to device the MLP model is on.
        Equivalent to using mlp.load_state_dict().
        
        :param parameters: Keys of parameters and weights with their tensors.
        :type parameters: dict[str, Tensor]
        """
        self.model.load_state_dict(parameters)

    def set_dataframe(self, csv_path: Path) -> None:
        """
        Load and cache self.dataframe for faster reuse if same csv file.
        
        :param csv_path: Filepath to csv.
        :type csv_path: Path
        """
        if self.dataframe_path is None or self.dataframe_path != csv_path:
            self.dataframe = pd.read_csv(csv_path, index_col='FlowID')
            self.dataframe_path = csv_path

    # Samples generated by the dataloader is on CPU instead of CUDA by default
    def get_flow_data(self, flow_ids: list[int]) -> tuple[Tensor, Tensor]:
        """
        Uses self.dataframe to transform table of features and label into
        tensors on self.config.device.

        Assumes label column is called 'label'.
        
        Binarizes multiclass labels. So preprocessed benign/normal traffic 
        should always be zero and malicious traffic should be a non-zero 
        integer label.
        
        :param flow_ids: Integers corresponding to FlowID (indices) to fetch
        features and labels from.
        :type flow_ids: list[int]
        :return: Tuple containing the features (2D) and the labels (1D).
        :rtype: tuple[Tensor, Tensor]s
        """
        if not hasattr(self, 'dataframe'):
            raise ValueError("Dataframe was not initialized")
        filtered = self.dataframe.loc[flow_ids]
        features, labels = filtered.drop('label', axis=1), filtered['label']
        np_features = features.to_numpy('float32')
        np_labels = labels.to_numpy('uint8')

        tensor_features = torch.from_numpy(np_features).to(self.config.device)
        tensor_labels = (
            torch.from_numpy(np_labels)
            .bool()
            .float()
            .to(self.config.device)
        )
        return tensor_features, tensor_labels

    def train(self, train_set: tuple[Tensor, Tensor]) -> float:
        """
        Trains local model modified by the toml configuration file 
        (such as continual learning and differential privacy), 
        updates model, and calculates the average loss.
        
        :param train_set: Data from self.get_flow_data() to be trained on.
        :type train_set: tuple[Tensor, Tensor]
        :return: Training loss of model.
        :rtype: float
        """
        self.model.train()

        if self.config.cl_enabled:
            train_set = self.cl.er.sample_replay_buffer(
                original_dataset=train_set,
                n_new_samples=len(train_set[1]),
                ratio_old_samples=self.config.er_mix_ratio,
            )

        data_loader = DataLoader(
            dataset=TensorDataset(*train_set),
            batch_size=self.config.batch_size,
            shuffle=True
        )
        # PrivacyEngine objects wrap around the original objects
        # N forward passes + N backward passes per batch (where N = batch size)
        # Time is relative to size of dataset to train
        packages = self._create_model_packages(data_loader)
        training_model, optimizer, data_loader = packages
        scheduler = self.model.get_scheduler(
            optimizer=optimizer,
            cosine_epochs=len(data_loader) * self.config.epochs
        )

        total_loss: float = 0.0
        total_samples: int = 0
        loop_start = time()
        for _ in range(self.config.epochs):
            loss, n_samples = self._train_iteration(
                model=training_model,
                optimizer=optimizer,
                scheduler=scheduler,
                data_loader=data_loader
            )
            total_loss += loss
            total_samples += n_samples
        print(f"Training Loop: {time() - loop_start} sec")

        if self.config.dp_enabled:
            self.model = training_model.to_standard_module()
            if self.stored_epsilon is not None:
                raise TypeError("Epsilon needs to be None from evaluation.")
            self.stored_epsilon = self.dp.get_epsilon(self.config.delta)

        if self.config.cl_enabled:
            self.cl.er.add_data(
                original_dataset=train_set,
                sample_rate=self.config.er_sample_rate,
            )

            self.cl.ewc.update_fisher_information(
                model=self.model,
                train_set=train_set,
                criterion=self.criterion,
                batch_size=self.config.batch_size
            )
            self.cl.ewc.update_prev_parameters(self.model)

        average_loss = total_loss / max(1, total_samples)
        return average_loss

    def _train_iteration(
            self,
            model: MLP | GradSampleModule,
            optimizer: Adam | DPOptimizer,
            scheduler: CosineAnnealingLR,
            data_loader: DataLoader
    ) -> tuple[float, int]:
        sum_loss: float = 0.0
        n_samples: int = 0
        for batch_features, batch_labels in data_loader:
            # Poisson sampling could produce empty batch
            if not batch_labels.nelement():
                continue
            batch_features: Tensor
            batch_labels: Tensor

            outputs: Tensor = model(batch_features) # Forward pass
            outputs = outputs.squeeze(1)
            loss: Tensor = self.criterion(outputs, batch_labels)

            if self.config.cl_enabled and not self.cl.ewc.is_empty():
                batch_fisher_penalty = self.cl.ewc.calculate_penalty(
                    model=model,
                    ewc_lambda=self.config.ewc_lambda
                )
                loss += batch_fisher_penalty

            loss.backward() # Calculate where to step using mini-batch SGD
            optimizer.step() # Step forward down gradient
            scheduler.step() # Adjust learning rate
            # Prevents gradient accumulation for next iteration
            optimizer.zero_grad()

            batch_size = len(batch_labels)
            sum_loss += loss.item() * batch_size
            n_samples += batch_size
        return sum_loss, n_samples

    def evaluate(self, test_set: tuple[Tensor, Tensor]) -> dict[str, float]:
        """
        Evaluates server aggregated model against the test set.
        
        :param test_set: Features and labels to process
        :type test_set: tuple[Tensor, Tensor]
        :return: Metrics from scoring the model.
        :rtype: dict[str, float]
        """
        self.model.eval()
        data_loader = DataLoader(
            dataset=TensorDataset(*test_set),
            batch_size=self.config.batch_size
        )
        packages = self._create_model_packages(data_loader)
        evaluation_model, _, data_loader = packages

        predictions_list: list[Tensor] = []
        probabilities_list: list[Tensor] = []
        labels_list: list[Tensor] =  []
        n_correct: int = 0
        total_loss: float = 0.0
        total_samples = 0

        with torch.no_grad():
            for batch_features, batch_labels in data_loader:
                if not batch_labels.nelement():
                    continue
                batch_features: Tensor
                batch_labels: Tensor

                outputs: Tensor = evaluation_model(batch_features)
                outputs = outputs.squeeze(1)
                probabilities: Tensor = torch.sigmoid(outputs)
                predictions: Tensor = (probabilities >= 0.5).float()

                n_batch_correct: Tensor = (predictions == batch_labels).sum()
                n_correct += int(n_batch_correct.item())
                batch_loss: Tensor = self.criterion(outputs, batch_labels)
                total_loss += batch_loss.item() * len(batch_labels)
                total_samples += len(batch_labels)

                predictions_list.append(predictions.cpu())
                probabilities_list.append(probabilities.cpu())
                labels_list.append(batch_labels.cpu())

        if self.config.dp_enabled:
            self.model = evaluation_model.to_standard_module()

        all_predictions = torch.cat(predictions_list)
        all_probabilities = torch.cat(probabilities_list)
        all_labels = torch.cat(labels_list)
        training_epsilon = -1 # Default sentinel value
        if self.stored_epsilon is not None:
            training_epsilon = self.stored_epsilon
            self.stored_epsilon = None
        metrics = {
            'accuracy': n_correct / total_samples,
            'loss': total_loss / total_samples,
            'roc-auc': FedMetrics.roc_auc(all_labels, all_probabilities),
            'pr-auc': FedMetrics.pr_auc(all_labels, all_probabilities),
            'macro-f1': FedMetrics.macro_f1(all_labels, all_predictions),
            'recall@fpr=1%': FedMetrics.recall_at_fpr(
                all_labels, all_probabilities, 0.01
            ),
            'epsilon': training_epsilon
        }
        return metrics

    def _create_model_packages(
            self,
            data_loader: DataLoader
    ) -> tuple[MLP | GradSampleModule, Adam | DPOptimizer, DataLoader]:
        if not self.config.dp_enabled:
            return self.model, self.model.get_optimizer(), data_loader
        if is_evaluating := not self.model.training:
            self.model.train()
        dp_model, dp_optimizer, *_, dp_data_loader = self.dp.make_private(
            module=self.model,
            optimizer=self.model.get_optimizer(),
            data_loader=data_loader,
            noise_multiplier=self.config.noise,
            max_grad_norm=self.config.clipping, # Clipping value
        )
        if is_evaluating:
            dp_model.eval()
        return dp_model, dp_optimizer, dp_data_loader

def _assign_client(function: Callable) -> Callable:
    """
    Initialize and cache client to context to maintain persistence.
    
    :param function: The client's train/evaluate function
    :type function: Callable
    :return: Wrapper that initializes the client.
    :rtype: Callable[..., Any]
    """
    def wrapper(msg: Message, context: Context) -> Message:
        context.client = getattr(context, 'client', Client(context))
        return function(context.client, msg)
    return wrapper

app = ClientApp()

@app.train()
@_assign_client
def client_train(client: Client, msg: Message) -> Message:
    """
    Initializes dataframe for client, trains, and constructs message to send
    back to server.
    
    :param client: Client object from context.client.
    :type client: Client
    :param msg: Message object sent from the server.
    :type msg: Message
    :return: Message reply back to the server containing training loss 
    and trained model parameters.
    :rtype: Message
    """
    new_parameters = msg.content['arrays'].to_torch_state_dict()
    client.update_model(new_parameters)
    dataframe_path = MAIN_PATH / 'datasets' / 'UAVIDS-2025 Preprocessed.csv'
    client.set_dataframe(dataframe_path)
    flow_ids: list[int] = msg.content['config']['flows']
    train_set = client.get_flow_data(flow_ids)

    average_loss = client.train(train_set)
    # state_dict() auto detaches, still would be on cuda
    client_array_record = ArrayRecord(OrderedDict(client.model.state_dict()))
    metrics = {
        'train_loss': average_loss,
        'num-examples': len(train_set[1])
    }
    content = RecordDict({
        'arrays': client_array_record,
        'metrics': MetricRecord(metrics)
    })
    return Message(content, reply_to=msg)

@app.evaluate()
@_assign_client
def client_evaluate(client: Client, msg: Message) -> Message:
    """
    Initializes dataframe for client, evaluates, and constructs message to send
    back to server. 
    
    :param client: Client object from context.client.
    :type client: Client
    :param msg: Message object sent from the server.
    :type msg: Message
    :return: Message reply back to the server containing training loss 
    and trained model parameters.
    :rtype: Message
    """
    new_parameters = msg.content['arrays'].to_torch_state_dict()
    client.update_model(new_parameters)
    dataframe_path = MAIN_PATH / 'datasets' / 'UAVIDS-2025 Preprocessed.csv'
    client.set_dataframe(dataframe_path)
    flow_ids: list[int] = msg.content['config']['flows']
    test_set = client.get_flow_data(flow_ids)

    metrics = client.evaluate(test_set)
    metrics['num-examples'] = len(test_set[1])
    metric_record = MetricRecord(metrics)
    content = RecordDict({'metrics': metric_record})
    return Message(content, reply_to=msg)
