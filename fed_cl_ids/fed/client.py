"""
Representation of a client/supernode in a federated framework.
Performs both training and evaluation with a local pytorch MLP module that gets
its parameters from the server module.
"""
from typing import Callable, Optional
from collections import OrderedDict
from dataclasses import dataclass
from pathlib import Path
from time import time
import os

import pandas as pd
import numpy as np

from flwr.app import ArrayRecord, Context, Message, MetricRecord, RecordDict
from flwr.clientapp import ClientApp

from opacus.grad_sample.grad_sample_module import GradSampleModule
from torch.utils.data import DataLoader, TensorDataset
from torch import Tensor
import torch

from fed_cl_ids.fed.continual_learning import (
    ReplayBuffer,
    ElasticWeightConsolidation
)
from fed_cl_ids.fed.differential_privacy import DifferentialPrivacy
from fed_cl_ids.models.losses import Losses
from fed_cl_ids.models.mlp import MLP

MAIN_PATH = Path().cwd() / 'fed_cl_ids'

@dataclass()
class ClientConfiguration:
    """Stores configurations from pyproject.toml"""
    def __init__(self, context: Context) -> None:
        device_str = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.device = torch.device(device_str)
        self.epochs = int(context.run_config['epochs'])
        self.batch_size = int(context.run_config['batch-size'])

        # Experience replay
        self.cl_enabled = bool(context.run_config['cl-enabled'])
        self.er_sample_rate = float(context.run_config['er-memory'])
        self.er_mix_ratio = float(context.run_config['er-mix-ratio'])
        self.ewc_lambda = float(context.run_config['ewc-lambda'])

        # Differential privacy
        self.dp_enabled = bool(context.run_config['dp-enabled'])
        self.clipping = float(context.run_config['clipping'])
        self.noise = float(context.run_config['noise'])
        self.delta = float(context.run_config['delta'])

class Client:
    """Acts as an interactive instance of a client."""
    def __init__(self, context: Context) -> None:
        self.config = ClientConfiguration(context)
        self.model: MLP = self._initialize_model(context)
        self.criterion = torch.nn.BCEWithLogitsLoss() # Automatically on device

        self.replay_buffer = ReplayBuffer(
            identifier=os.getpid(),
            path=MAIN_PATH / 'runtime'
        )
        self.ewc = ElasticWeightConsolidation()
        self.dp = DifferentialPrivacy()
        # Get epsilon with train, return with evaluate.
        self.stored_epsilon: Optional[float] = None

        # Data cache (probably will be removed with CIC-IDS)
        self.dataframe: pd.DataFrame
        self.dataframe_path: Optional[Path] = None

    def _initialize_model(self, context: Context) -> MLP:
        widths = str(context.run_config['mlp-widths'])
        model = MLP(
            n_features=int(context.run_config['n-features']),
            hidden_widths=map(int, widths.split(',')),
            dropout=float(context.run_config['mlp-dropout']),
            weight_decay=float(context.run_config['mlp-weight-decay']),
            lr_max=float(context.run_config['mlp-lr-max']),
            lr_min=float(context.run_config['mlp-lr-min'])
        )
        return model.to(self.config.device)

    def update_model(self, parameters: dict[str, Tensor]) -> None:
        """
        Load a given MLP module's parameters into client's model.
        Equivalent to using load_state_dict().
        
        :param parameters: Keys of parameters and weights with their tensors.
        :type parameters: dict[str, Tensor]
        """
        self.model.load_state_dict(parameters)
        self.model = self.model.to(self.config.device)

    def set_dataframe(self, csv_path: Path) -> None:
        """
        Load and cache self.dataframe for faster reuse if same csv file.
        
        :param csv_path: Filepath to csv.
        :type csv_path: Path
        """
        if self.dataframe_path is not None and self.dataframe_path == csv_path:
            return
        self.dataframe = pd.read_csv(csv_path, index_col='FlowID')
        self.dataframe_path = csv_path

    # Samples generated by the dataloader is on CPU instead of CUDA by default
    def get_flow_data(self, flow_ids: list[int]) -> tuple[Tensor, Tensor]:
        """
        Uses self.dataframe to transform table of features and label into
        tensors on self.config.device.

        Assumes label column is called 'label'.
        
        Binarizes multiclass labels. So preprocessed benign/normal traffic 
        should always be zero and malicious traffic should be a non-zero 
        integer label.
        
        :param flow_ids: Integers corresponding to FlowID (indices) to fetch
        features and labels from.
        :type flow_ids: list[int]
        :return: Tuple containing the features (2D) and the labels (1D).
        :rtype: tuple[Tensor, Tensor]
        """
        if not hasattr(self, 'dataframe'):
            raise ValueError("Dataframe was not initialized")
        filtered = self.dataframe.loc[flow_ids]
        features, labels = filtered.drop('label', axis=1), filtered['label']
        np_features = features.to_numpy('float32')
        np_labels = labels.to_numpy('uint8')

        tensor_features = torch.from_numpy(np_features).to(self.config.device)
        # Labels are floats since BCELoss only accepts floats
        tensor_labels = (
            torch.from_numpy(np_labels)
            .bool()
            .float()
            .to(self.config.device)
        )
        return tensor_features, tensor_labels

    def train(self, train_set: tuple[Tensor, Tensor]) -> float:
        """
        Trains local model modified by the toml configuration file 
        (such as continual learning and differential privacy), 
        updates model, and calculates the average loss.
        
        :param train_set: Data from self.get_flow_data() to be trained on.
        :type train_set: tuple[Tensor, Tensor]
        :return: Training loss of model.
        :rtype: float
        """
        self.model.train()
        train_features, train_labels = train_set
        n_new_samples = len(train_labels)

        if self.config.cl_enabled:
            if samples := self._sample_replay_buffer(n_new_samples):
                old_features, old_labels = samples
                old_features = old_features.to(self.config.device)
                old_labels = old_labels.to(self.config.device)
                train_features = torch.cat((train_features, old_features))
                train_labels = torch.cat((train_labels, old_labels))

        data = TensorDataset(train_features, train_labels)
        data_loader = DataLoader(
            dataset=data,
            batch_size=self.config.batch_size,
            shuffle=True,
        )
        training_model: MLP | GradSampleModule = self.model
        optimizer = self.model.get_optimizer()
        iterations = len(data_loader) * self.config.epochs
        scheduler = self.model.get_scheduler(optimizer, iterations)

        # PrivacyEngine objects wrap around the original objects
        # N forward passes + N backward passes per batch (where N = batch size)
        # Time is relative to size of dataset to train
        if self.config.dp_enabled:
            training_model, optimizer, *_, data_loader = self.dp.make_private(
                module=self.model,
                optimizer=optimizer,
                data_loader=data_loader,
                noise_multiplier=self.config.noise,
                max_grad_norm=self.config.clipping, # Clipping
            )

        running_loss = 0.0
        loop_start = time()
        for _ in range(self.config.epochs):
            for batch_features, batch_labels in data_loader:
                batch_features: Tensor
                batch_labels: Tensor
                # Poisson sampling could produce empty batch
                if not batch_labels.nelement():
                    continue

                outputs: Tensor = training_model(batch_features) # Forward pass
                outputs = outputs.squeeze(1)
                loss: Tensor = self.criterion(outputs, batch_labels)

                if self.config.cl_enabled and not self.ewc.is_empty():
                    minibatch_penalty = self.ewc.calculate_penalty(
                        model=training_model,
                        lambda_penalty=self.config.ewc_lambda
                    )
                    loss += minibatch_penalty

                loss.backward() # Calculate where to step using mini-batch SGD
                optimizer.step() # Step forward down gradient
                scheduler.step() # Adjust learning rate
                # Prevents gradient accumulation for next iteration
                optimizer.zero_grad()
                running_loss += loss.item() * len(batch_labels)
        print(f"{time() - loop_start=}")

        if self.config.dp_enabled:
            self.model = training_model.to_standard_module()

        if self.config.cl_enabled:
            new_features, new_labels = train_set
            rng_values = torch.rand(size=(len(new_labels),), device=self.config.device)
            mask = rng_values <= self.config.er_sample_rate
            self.replay_buffer.append(new_features[mask], new_labels[mask])

            self.ewc.update_fisher_information(
                model=self.model,
                train_set=train_set,
                criterion=self.criterion,
                batch_size=self.config.batch_size
            )
            self.ewc.update_prev_parameters(self.model)

        total_samples = max(1, len(train_labels))
        avg_loss = running_loss / total_samples
        return avg_loss

    def _sample_replay_buffer(self, n_new_samples: int) -> Optional[tuple[Tensor, Tensor]]:
        """
        Randomly sample from replay buffer to achieve ratio
        (from configuration file). If ratio is zero or replay buffer is empty,
        return None.

        :param n_new_samples: Number of samples in the current batch.
        Used to calculate how many previous samples to retrieve.
        :type n_new_samples: int
        :return: Features and labels as tensors or None if empty buffer,
        samples, or ratio
        :rtype: tuple[Tensor, Tensor] | None
        """
        if not self.config.er_mix_ratio or not n_new_samples:
            return None
        if self.config.er_mix_ratio >= 1.0:
            raise ValueError("Experience replay cannot be 100%")
        # Could also do: (new_samples * 0.2) / 0.8 = 20% of total (mix = 0.2)
        true_ratio = (1 - self.config.er_mix_ratio) / self.config.er_mix_ratio
        ideal_sample_size = int(n_new_samples / true_ratio)
        actual_sample_size = min(len(self.replay_buffer), ideal_sample_size)
        if not actual_sample_size:
            return None
        # Ratio will be off until replay buffer size >= replay sample size
        return self.replay_buffer.sample(actual_sample_size)

    def evaluate(self, test_set: tuple[Tensor, Tensor]) -> dict[str, float]:
        """
        Evaluates server aggregated model against the test set.
        
        :param test_set: Features and labels to process
        :type test_set: tuple[Tensor, Tensor]
        :return: Metrics from scoring the model.
        :rtype: dict[str, float]
        """
        self.model.eval()
        test_features, test_labels = test_set
        data = TensorDataset(test_features, test_labels)
        data_loader = DataLoader(data, batch_size=self.config.batch_size)

        all_predictions, all_probabilities =  [], []
        n_correct: int = 0
        total_loss: float = 0.0

        with torch.no_grad():
            for batch_features, batch_labels in data_loader:
                batch_features: Tensor
                batch_labels: Tensor
                outputs: Tensor = self.model(batch_features)
                outputs = outputs.squeeze(1)
                probabilities = torch.sigmoid(outputs) # auto on self.config.device
                predictions = (probabilities >= 0.5).float()

                n_batch_correct: Tensor = (predictions == batch_labels).sum()
                n_correct += int(n_batch_correct.item())
                batch_loss: Tensor = self.criterion(outputs, batch_labels)
                total_loss += batch_loss.item() * len(batch_labels)

                all_predictions.extend(predictions.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())

        all_predictions = np.array(all_predictions)
        all_probabilities = np.array(all_probabilities)
        all_labels = test_labels.cpu().numpy()
        total_samples = len(test_set[1])

        metrics = {
            'accuracy': n_correct / total_samples,
            'loss': total_loss / total_samples,
            'roc-auc': Losses.roc_auc(all_labels, all_probabilities),
            'pr-auc': Losses.pr_auc(all_labels, all_probabilities),
            'macro-f1': Losses.macro_f1(all_labels, all_predictions),
            'recall@fpr=1%': Losses.recall_at_fpr(all_labels, all_probabilities, 0.01)
        }
        return metrics

def assign_context(function: Callable) -> Callable:
    """
    Initialize and cache client to context to maintain persistence.
    
    :param function: The client's train/evaluate function
    :type function: Callable
    :return: Wrapper that initializes the client.
    :rtype: Callable[..., Any]
    """
    def wrapper(msg: Message, context: Context) -> Message:
        context.client = getattr(context, 'client', Client(context))
        return function(context.client, msg)
    return wrapper

app = ClientApp()

@app.train()
@assign_context
def client_train(client: Client, msg: Message) -> Message:
    """
    Initializes dataframe for client, trains, and constructs message to send
    back to server.
    
    :param client: Client object from context.client.
    :type client: Client
    :param msg: Message object sent from the server.
    :type msg: Message
    :return: Message reply back to the server containing training loss 
    and trained model parameters.
    :rtype: Message
    """
    new_parameters = msg.content['arrays'].to_torch_state_dict()
    client.update_model(new_parameters)
    dataframe_path = MAIN_PATH / 'datasets' / 'UAVIDS-2025 Preprocessed.csv'
    client.set_dataframe(dataframe_path)
    flow_ids: list[int] = msg.content['config']['flows']
    train_set = client.get_flow_data(flow_ids)

    average_loss = client.train(train_set)
    # state_dict() auto detaches
    client_params = OrderedDict(client.model.state_dict())
    client_array_record = ArrayRecord(client_params)
    metrics = {
        'train_loss': average_loss,
        'num-examples': len(train_set[1])
    }
    metric_record = MetricRecord(metrics)
    content = RecordDict({
        'arrays': client_array_record,
        'metrics': metric_record
    })
    return Message(content, reply_to=msg)

@app.evaluate()
@assign_context
def client_evaluate(client: Client, msg: Message) -> Message:
    """
    Initializes dataframe for client, evaluates, and constructs message to send
    back to server. 
    
    :param client: Client object from context.client.
    :type client: Client
    :param msg: Message object sent from the server.
    :type msg: Message
    :return: Message reply back to the server containing training loss 
    and trained model parameters.
    :rtype: Message
    """
    new_parameters = msg.content['arrays'].to_torch_state_dict()
    client.update_model(new_parameters)
    dataframe_path = MAIN_PATH / 'datasets' / 'UAVIDS-2025 Preprocessed.csv'
    client.set_dataframe(dataframe_path)
    flow_ids: list[int] = msg.content['config']['flows']
    test_set = client.get_flow_data(flow_ids)

    metrics = client.evaluate(test_set)
    metrics['num-examples'] = len(test_set[1])
    metric_record = MetricRecord(metrics)
    content = RecordDict({'metrics': metric_record})
    return Message(content=content, reply_to=msg)
